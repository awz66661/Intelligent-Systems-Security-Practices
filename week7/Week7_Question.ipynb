{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Two-Step对抗训练\n",
    "\n",
    "- 在前两周的实验中，你已经实现了简单的单步对抗攻击（FGSM）和迭代对抗攻击（PGD）；\n",
    "\n",
    "- 在本周的第一个实验中，请实现一个Two-Step对抗训练防御算法，并测试其在训练集、测试集上的预测表现，以及其对FGSM、PGD的防御效果；\n",
    "\n",
    "- 具体实验步骤如下：\n",
    "\n",
    "  1. 将代码文件（Python文件与Notebook文件）上传到服务器端根目录；\n",
    "\n",
    "  2. 将样本数据（Week567_img_label.pkl）上传至服务器端data/目录下；\n",
    "\n",
    "  3. 将之前训练的模型参数（lenet5.pt）上传至服务器端model/目录下；\n",
    "\n",
    "  4. 依照提示，完成**Python文件**与**Notebook文件**中的TODO内容；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)\n",
    "from Week567_General_Code_Question import LeNet5, load_mnist, fgsm, pgd\n",
    "from Week567_General_Code_Question import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "batch_size = 128\n",
    "epsilon = 0.2\n",
    "iter = 20\n",
    "alpha = 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = LeNet5()\n",
    "model.load_state_dict(torch.load('model/lenet5.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Data\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loader, test_loader = load_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成对抗样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:50<00:00,  4.24it/s]\n"
     ]
    }
   ],
   "source": [
    "fgsm_imgs, pgd_imgs, labels = [], [], []\n",
    "\n",
    "for img, label in tqdm(train_loader):\n",
    "    # benign imgs\n",
    "    fgsm_imgs.append(img)\n",
    "    pgd_imgs.append(img)\n",
    "    labels.append(label)\n",
    "\n",
    "    # adv imgs\n",
    "    fgsm_img = fgsm(img, epsilon, model, criterion, label)\n",
    "    fgsm_imgs.append(fgsm_img)\n",
    "    \n",
    "    pgd_img = pgd(img, epsilon, iter, model, criterion, label)\n",
    "    pgd_imgs.append(pgd_img)\n",
    "    labels.append(label)\n",
    "\n",
    "fgsm_imgs = torch.cat(fgsm_imgs, dim=0).detach()\n",
    "pgd_imgs = torch.cat(pgd_imgs, dim=0).detach()\n",
    "labels = torch.cat(labels, dim=0).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm_trainset = torch.utils.data.TensorDataset(fgsm_imgs, labels)\n",
    "pgd_trainset = torch.utils.data.TensorDataset(pgd_imgs, labels)\n",
    "fgsm_trainloader = torch.utils.data.DataLoader(fgsm_trainset, batch_size=batch_size * 2, shuffle=False)\n",
    "pgd_trainloader = torch.utils.data.DataLoader(pgd_trainset, batch_size=batch_size * 2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现Two-Step对抗训练\n",
    "- 请在下面的block中实现基于FGSM/PGD的Two-Step对抗训练攻击\n",
    "  - adv_train_two_step(data_loader, epoch, lr, criterion, adv_loss_weight=1)\n",
    "- 算法流程\n",
    "  - 从dataloader中取出成对的正常样本和对抗样本，分别计算loss然后求和，再反传梯度更新模型\n",
    "  > tips: “分别计算loss”便于我们为不同的loss赋予不同的权重\n",
    "    > - benign_loss前面乘上一个较大的系数，就会使模型更倾向于准确预测正常样本；\n",
    "    > - adv_loss前面乘上一个较大的系数，就会使模型更倾向于准确预测对抗样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_train_two_step(data_loader, epoch, lr, criterion, adv_loss_weight=1):\n",
    "    model = LeNet5()\n",
    "    model.load_state_dict(torch.load('model/lenet5.pt'))\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for e in range(epoch):\n",
    "        t = tqdm(data_loader)\n",
    "        for img, label in t:\n",
    "            # 将数据平均分为两部分\n",
    "            benign_img, benign_label = img[:img.shape[0] // 2], label[:label.shape[0] // 2]\n",
    "            adv_img, adv_label = img[img.shape[0] // 2:], label[label.shape[0] // 2:]\n",
    "\n",
    "            # TODO: Forward and compute loss for benign samples\n",
    "            benign_loss = 0.\n",
    "            # 打印benign_img的通道数\n",
    "            # print(benign_img.shape)\n",
    "            o = model(benign_img)\n",
    "            benign_loss = criterion(o, benign_label)\n",
    "\n",
    "            \n",
    "            # TODO: Forward and compute loss for adversarial examples\n",
    "            adv_loss = 0.\n",
    "            o = model(adv_img)\n",
    "            adv_loss = criterion(o, adv_label)\n",
    "            \n",
    "            # TODO: Calculate the total loss, then backward\n",
    "  \n",
    "            loss = benign_loss + adv_loss_weight * adv_loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            t.set_postfix(epoch=e, benign_loss=benign_loss.item(), adv_loss=adv_loss.item())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用fgsm进行对抗训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 43.88it/s, adv_loss=0.586, benign_loss=0.291, epoch=0] \n",
      "100%|██████████| 469/469 [00:10<00:00, 42.88it/s, adv_loss=0.271, benign_loss=0.225, epoch=1]  \n",
      "100%|██████████| 469/469 [00:11<00:00, 40.87it/s, adv_loss=0.155, benign_loss=0.179, epoch=2]  \n",
      "100%|██████████| 469/469 [00:11<00:00, 39.08it/s, adv_loss=0.103, benign_loss=0.153, epoch=3]  \n",
      "100%|██████████| 469/469 [00:11<00:00, 41.26it/s, adv_loss=0.0784, benign_loss=0.141, epoch=4] \n",
      "100%|██████████| 469/469 [00:10<00:00, 44.43it/s, adv_loss=0.0589, benign_loss=0.127, epoch=5]  \n",
      "100%|██████████| 469/469 [00:10<00:00, 44.49it/s, adv_loss=0.0448, benign_loss=0.118, epoch=6]   \n",
      "100%|██████████| 469/469 [00:10<00:00, 44.90it/s, adv_loss=0.0358, benign_loss=0.108, epoch=7]   \n",
      "100%|██████████| 469/469 [00:10<00:00, 43.79it/s, adv_loss=0.0297, benign_loss=0.102, epoch=8]   \n",
      "100%|██████████| 469/469 [00:10<00:00, 44.07it/s, adv_loss=0.0244, benign_loss=0.0932, epoch=9]  \n",
      "100%|██████████| 469/469 [00:10<00:00, 43.66it/s, adv_loss=0.0209, benign_loss=0.0888, epoch=10]  \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.41it/s, adv_loss=0.0179, benign_loss=0.0851, epoch=11]  \n",
      "100%|██████████| 469/469 [00:11<00:00, 41.94it/s, adv_loss=0.0149, benign_loss=0.0821, epoch=12]  \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.02it/s, adv_loss=0.013, benign_loss=0.0797, epoch=13]   \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.56it/s, adv_loss=0.0114, benign_loss=0.077, epoch=14]   \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.33it/s, adv_loss=0.0102, benign_loss=0.0742, epoch=15]  \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.04it/s, adv_loss=0.00895, benign_loss=0.0719, epoch=16] \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.33it/s, adv_loss=0.00802, benign_loss=0.07, epoch=17]   \n",
      "100%|██████████| 469/469 [00:11<00:00, 41.93it/s, adv_loss=0.00725, benign_loss=0.0681, epoch=18] \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.22it/s, adv_loss=0.00653, benign_loss=0.0661, epoch=19]  \n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "epoch = 20\n",
    "\n",
    "cnn_fgsm_two_step = adv_train_two_step(fgsm_trainloader, epoch, lr, criterion)\n",
    "torch.save(cnn_fgsm_two_step.state_dict(), 'model/cnn_fgsm_two_step.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用pgd进行对抗训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 43.28it/s, adv_loss=0.548, benign_loss=0.302, epoch=0]\n",
      "100%|██████████| 469/469 [00:10<00:00, 46.28it/s, adv_loss=0.284, benign_loss=0.217, epoch=1]  \n",
      "100%|██████████| 469/469 [00:10<00:00, 46.19it/s, adv_loss=0.188, benign_loss=0.165, epoch=2]  \n",
      "100%|██████████| 469/469 [00:10<00:00, 43.65it/s, adv_loss=0.134, benign_loss=0.141, epoch=3]  \n",
      "100%|██████████| 469/469 [00:12<00:00, 37.21it/s, adv_loss=0.101, benign_loss=0.127, epoch=4]  \n",
      "100%|██████████| 469/469 [00:10<00:00, 45.32it/s, adv_loss=0.0847, benign_loss=0.12, epoch=5]  \n",
      "100%|██████████| 469/469 [00:10<00:00, 43.52it/s, adv_loss=0.0667, benign_loss=0.113, epoch=6]  \n",
      "100%|██████████| 469/469 [00:10<00:00, 46.16it/s, adv_loss=0.0575, benign_loss=0.111, epoch=7]  \n",
      "100%|██████████| 469/469 [00:10<00:00, 45.73it/s, adv_loss=0.0473, benign_loss=0.103, epoch=8]   \n",
      "100%|██████████| 469/469 [00:10<00:00, 46.00it/s, adv_loss=0.0378, benign_loss=0.0957, epoch=9]  \n",
      "100%|██████████| 469/469 [00:10<00:00, 45.75it/s, adv_loss=0.0303, benign_loss=0.088, epoch=10]   \n",
      "100%|██████████| 469/469 [00:10<00:00, 45.82it/s, adv_loss=0.0243, benign_loss=0.0811, epoch=11]  \n",
      "100%|██████████| 469/469 [00:10<00:00, 46.30it/s, adv_loss=0.0211, benign_loss=0.0753, epoch=12]  \n",
      "100%|██████████| 469/469 [00:10<00:00, 45.79it/s, adv_loss=0.0179, benign_loss=0.0711, epoch=13]  \n",
      "100%|██████████| 469/469 [00:10<00:00, 45.99it/s, adv_loss=0.0164, benign_loss=0.069, epoch=14]   \n",
      "100%|██████████| 469/469 [00:10<00:00, 45.58it/s, adv_loss=0.0146, benign_loss=0.065, epoch=15]   \n",
      "100%|██████████| 469/469 [00:10<00:00, 45.52it/s, adv_loss=0.0133, benign_loss=0.0612, epoch=16]  \n",
      "100%|██████████| 469/469 [00:10<00:00, 44.65it/s, adv_loss=0.0124, benign_loss=0.0586, epoch=17]  \n",
      "100%|██████████| 469/469 [00:10<00:00, 45.70it/s, adv_loss=0.0114, benign_loss=0.055, epoch=18]   \n",
      "100%|██████████| 469/469 [00:10<00:00, 45.85it/s, adv_loss=0.0107, benign_loss=0.0539, epoch=19]  \n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "epoch = 20\n",
    "\n",
    "cnn_pgd_two_step = adv_train_two_step(pgd_trainloader, epoch, lr, criterion)\n",
    "torch.save(cnn_pgd_two_step.state_dict(), 'model/cnn_pgd_two_step.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评测模型性能\n",
    "- 请在Python文件Week567_General_Code_Question.py中补全函数如下：\n",
    "  - 在`evaluate_dataloader(dataloader, model)`函数实现模型测试过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Week567_General_Code_Question import evaluate_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 测试基于FGSM执行Two-Step对抗训练的CNN的预测质量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 57.12it/s, test_acc=0.984]\n"
     ]
    }
   ],
   "source": [
    "evaluate_dataloader(test_loader, cnn_fgsm_two_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 测试基于PGD执行Two-Step对抗训练的CNN的预测质量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 59.39it/s, test_acc=0.985]\n"
     ]
    }
   ],
   "source": [
    "evaluate_dataloader(test_loader, cnn_pgd_two_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评测防御效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 28, 28]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "with open('data/Week567_img_label.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    imgs, labels = data['img'], data['label']\n",
    "    print(imgs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 评测基于FGSM执行Two-Step对抗训练的模型针对FGSM/PGD攻击的防御效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For FGSM Two-Step.\n",
      "\n",
      "Against FGSM:\n",
      "torch.Size([20, 1, 28, 28])\n",
      "match rate: 0.7\n",
      "Against PGD:\n",
      "match rate: 0.3\n"
     ]
    }
   ],
   "source": [
    "print(\"For FGSM Two-Step.\\n\")\n",
    "print(\"Against FGSM:\")\n",
    "epsilon = 0.08\n",
    "\n",
    "print(imgs.shape)\n",
    "adv_xs = fgsm(imgs, epsilon, cnn_fgsm_two_step, criterion, labels)\n",
    "pred_label = evaluate(adv_xs, labels, cnn_fgsm_two_step)\n",
    "\n",
    "\n",
    "print(\"Against PGD:\")\n",
    "alpha = 0.07\n",
    "iter = 30\n",
    "\n",
    "adv_xs = pgd(imgs, epsilon, iter, cnn_fgsm_two_step, criterion, labels)\n",
    "\n",
    "pred_label = evaluate(adv_xs, labels, cnn_fgsm_two_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 评测基于PGD执行Two-Step对抗训练的模型针对FGSM/PGD攻击的防御效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For PGD Two-Step.\n",
      "\n",
      "Against FGSM:\n",
      "match rate: 0.65\n",
      "Against PGD:\n",
      "match rate: 0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"For PGD Two-Step.\\n\")\n",
    "print(\"Against FGSM:\")\n",
    "epsilon = 0.08\n",
    "\n",
    "adv_xs = fgsm(imgs, epsilon, cnn_pgd_two_step, criterion, labels)\n",
    "pred_label = evaluate(adv_xs, labels, cnn_pgd_two_step)\n",
    "\n",
    "\n",
    "print(\"Against PGD:\")\n",
    "alpha = 0.07\n",
    "iter = 30\n",
    "\n",
    "adv_xs = pgd(imgs, epsilon, iter, cnn_pgd_two_step, criterion, labels)\n",
    "\n",
    "pred_label = evaluate(adv_xs, labels, cnn_pgd_two_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 迭代对抗训练\n",
    "\n",
    "- 在上一部分中，你已经实现了第一个对抗防御算法；\n",
    "- 接下来，请模仿**Two-Step对抗训练**算法实现**迭代对抗训练**算法，并测试其在训练集、测试集上的预测表现，以及其对FGSM、PGD的防御效果；\n",
    "\n",
    "- 具体实验步骤如下：\n",
    "\n",
    "  1. 将代码文件（Python文件与Notebook文件）上传到服务器端根目录；\n",
    "\n",
    "  2. 将样本数据（Week567_img_label.pkl）上传至服务器端data/目录下；\n",
    "\n",
    "  3. 将之前训练的模型参数（lenet5.pt）上传至服务器端model/目录下；\n",
    "\n",
    "  4. 依照提示，完成**Notebook文件**中的TODO内容；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现迭代对抗训练\n",
    "- 请在下面的block中分别实现基于FGSM和PGD的迭代对抗训练攻击函数：\n",
    "  - adv_train_iter_fgsm(data_loader, epoch, lr, criterion, epsilon, adv_loss_weight=1.)\n",
    "  - adv_train_iter_pgd(data_loader, epoch, lr, criterion, epsilon, iter=20, adv_loss_weight=1.)\n",
    "- 算法流程\n",
    "  1. 从data_loader中取出正常样本对(img,label)\n",
    "  2. 使用之前实现的FGSM/PGD算法，基于(img,label)生成对抗样本(adv_img,label)\n",
    "      > tips: 之前版本实现的FGSM/PGD算法最后包含了`.detach()`操作，因此梯度不会传递到adv_img上\n",
    "  3. 基于正常样本和对抗样本分别计算loss然后求和，再反传梯度更新模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 基于FGSM迭代对抗训练cnn模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_train_iter_fgsm(data_loader, epoch, lr, criterion, epsilon, adv_loss_weight=1.):\n",
    "    model = LeNet5()\n",
    "    model.load_state_dict(torch.load('model/lenet5.pt'))\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for e in range(epoch):\n",
    "        t = tqdm(data_loader)\n",
    "        for img, label in t:\n",
    "            # TODO: Forward and compute loss for benign samples\n",
    "            benign_loss = 0.\n",
    "            o = model(img)\n",
    "            benign_loss = criterion(o, label)\n",
    "\n",
    "\n",
    "            # TODO: Generate the adversarial samples, then forward and compute loss for adversarial examples\n",
    "            adv_img = None\n",
    "            adv_loss = 0.\n",
    "            adv_img = fgsm(img, epsilon, model, criterion, label)\n",
    "            o = model(adv_img)\n",
    "            adv_loss = criterion(o, label)\n",
    "\n",
    "            \n",
    "            # TODO: Calculate the total loss, then backward\n",
    "            loss = benign_loss + adv_loss_weight * adv_loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            t.set_postfix(epoch=e, benign_loss=benign_loss.item(), adv_loss=adv_loss.item())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:19<00:00, 23.52it/s, adv_loss=1.21, benign_loss=0.134, epoch=0] \n",
      "100%|██████████| 469/469 [00:19<00:00, 23.52it/s, adv_loss=1.18, benign_loss=0.219, epoch=1]  \n",
      "100%|██████████| 469/469 [00:19<00:00, 23.92it/s, adv_loss=0.838, benign_loss=0.0958, epoch=2]\n",
      "100%|██████████| 469/469 [00:19<00:00, 23.97it/s, adv_loss=0.736, benign_loss=0.0857, epoch=3]\n",
      "100%|██████████| 469/469 [00:21<00:00, 22.20it/s, adv_loss=0.761, benign_loss=0.135, epoch=4] \n",
      "100%|██████████| 469/469 [00:20<00:00, 22.53it/s, adv_loss=0.89, benign_loss=0.188, epoch=5]  \n",
      "100%|██████████| 469/469 [00:19<00:00, 24.05it/s, adv_loss=0.613, benign_loss=0.0912, epoch=6]\n",
      "100%|██████████| 469/469 [00:19<00:00, 23.84it/s, adv_loss=0.532, benign_loss=0.0809, epoch=7]\n",
      "100%|██████████| 469/469 [00:19<00:00, 24.00it/s, adv_loss=0.503, benign_loss=0.0348, epoch=8]\n",
      "100%|██████████| 469/469 [00:20<00:00, 22.93it/s, adv_loss=0.643, benign_loss=0.142, epoch=9]  \n",
      "100%|██████████| 469/469 [00:20<00:00, 23.32it/s, adv_loss=0.892, benign_loss=0.0806, epoch=10] \n",
      "100%|██████████| 469/469 [00:19<00:00, 23.94it/s, adv_loss=0.259, benign_loss=0.01, epoch=11]   \n",
      "100%|██████████| 469/469 [00:19<00:00, 24.03it/s, adv_loss=0.54, benign_loss=0.0633, epoch=12]  \n",
      "100%|██████████| 469/469 [00:19<00:00, 24.01it/s, adv_loss=0.338, benign_loss=0.0157, epoch=13] \n",
      "100%|██████████| 469/469 [00:19<00:00, 24.05it/s, adv_loss=0.467, benign_loss=0.0684, epoch=14] \n",
      "100%|██████████| 469/469 [00:19<00:00, 23.75it/s, adv_loss=0.599, benign_loss=0.0665, epoch=15]\n",
      "100%|██████████| 469/469 [00:24<00:00, 18.83it/s, adv_loss=0.56, benign_loss=0.0816, epoch=16]  \n",
      "100%|██████████| 469/469 [00:21<00:00, 21.90it/s, adv_loss=0.402, benign_loss=0.0779, epoch=17] \n",
      "100%|██████████| 469/469 [00:20<00:00, 22.85it/s, adv_loss=0.321, benign_loss=0.0165, epoch=18] \n",
      "100%|██████████| 469/469 [00:20<00:00, 22.89it/s, adv_loss=0.421, benign_loss=0.041, epoch=19]  \n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "epoch = 20\n",
    "adv_loss_weight = 1.0\n",
    "\n",
    "epsilon = 0.2\n",
    "\n",
    "cnn_fgsm_iter = adv_train_iter_fgsm(train_loader, epoch, lr, criterion, epsilon, adv_loss_weight)\n",
    "torch.save(cnn_fgsm_iter.state_dict(), 'model/cnn_fgsm_iter.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 基于PGD迭代对抗训练cnn模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_train_iter_pgd(data_loader, epoch, lr, criterion, epsilon, iter=20, adv_loss_weight=1.):\n",
    "    model = LeNet5()\n",
    "    model.load_state_dict(torch.load('model/lenet5.pt'))\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for e in range(epoch):\n",
    "        t = tqdm(data_loader)\n",
    "        for img, label in t:\n",
    "            # TODO: Forward and compute loss for benign samples\n",
    "            benign_loss = 0.\n",
    "            o = model(img)\n",
    "            benign_loss = criterion(o, label)\n",
    "\n",
    "\n",
    "            # TODO: Generate the adversarial samples, then forward and compute loss for adversarial examples\n",
    "            adv_img = None\n",
    "            adv_loss = 0.\n",
    "            #print(\"Tensor version before operation1:\", img._version)\n",
    "            imgpgd = img.clone().detach().requires_grad_(True)\n",
    "            adv_img = pgd(imgpgd, epsilon, iter, model, criterion, label)\n",
    "            #print(\"Tensor version before operation2:\", img._version)\n",
    "            o = model(adv_img)\n",
    "            adv_loss = criterion(o, label)\n",
    "\n",
    "            \n",
    "            # TODO: Calculate the total loss, then backward\n",
    "            loss = benign_loss + adv_loss_weight * adv_loss\n",
    "            optimizer.zero_grad()\n",
    "            #print(\"Tensor version before operation3:\", img._version)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t.set_postfix(epoch=e, benign_loss=benign_loss.item(), adv_loss=adv_loss.item())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:58<00:00,  3.97it/s, adv_loss=1.39, benign_loss=0.213, epoch=0]\n",
      "100%|██████████| 469/469 [01:55<00:00,  4.08it/s, adv_loss=1.3, benign_loss=0.256, epoch=1]  \n",
      "100%|██████████| 469/469 [01:54<00:00,  4.11it/s, adv_loss=0.95, benign_loss=0.126, epoch=2]  \n",
      "100%|██████████| 469/469 [01:52<00:00,  4.17it/s, adv_loss=0.757, benign_loss=0.122, epoch=3] \n",
      "100%|██████████| 469/469 [01:52<00:00,  4.18it/s, adv_loss=0.724, benign_loss=0.113, epoch=4] \n",
      "100%|██████████| 469/469 [01:51<00:00,  4.19it/s, adv_loss=0.78, benign_loss=0.0971, epoch=5] \n",
      "100%|██████████| 469/469 [01:51<00:00,  4.19it/s, adv_loss=0.917, benign_loss=0.12, epoch=6]  \n",
      "100%|██████████| 469/469 [01:52<00:00,  4.19it/s, adv_loss=0.676, benign_loss=0.104, epoch=7] \n",
      "100%|██████████| 469/469 [01:51<00:00,  4.20it/s, adv_loss=0.535, benign_loss=0.0654, epoch=8]\n",
      "100%|██████████| 469/469 [01:51<00:00,  4.21it/s, adv_loss=0.522, benign_loss=0.0514, epoch=9]\n",
      "100%|██████████| 469/469 [01:51<00:00,  4.20it/s, adv_loss=0.448, benign_loss=0.0548, epoch=10]\n",
      "100%|██████████| 469/469 [01:51<00:00,  4.21it/s, adv_loss=0.671, benign_loss=0.102, epoch=11] \n",
      "100%|██████████| 469/469 [01:51<00:00,  4.22it/s, adv_loss=0.507, benign_loss=0.0613, epoch=12]\n",
      "100%|██████████| 469/469 [01:50<00:00,  4.23it/s, adv_loss=0.32, benign_loss=0.017, epoch=13]  \n",
      "100%|██████████| 469/469 [01:51<00:00,  4.22it/s, adv_loss=0.345, benign_loss=0.0339, epoch=14]\n",
      "100%|██████████| 469/469 [01:51<00:00,  4.22it/s, adv_loss=0.415, benign_loss=0.0445, epoch=15]\n",
      "100%|██████████| 469/469 [01:51<00:00,  4.21it/s, adv_loss=0.471, benign_loss=0.0498, epoch=16]\n",
      "100%|██████████| 469/469 [01:51<00:00,  4.19it/s, adv_loss=0.426, benign_loss=0.0727, epoch=17]\n",
      "100%|██████████| 469/469 [01:51<00:00,  4.21it/s, adv_loss=0.468, benign_loss=0.0458, epoch=18]\n",
      "100%|██████████| 469/469 [01:51<00:00,  4.23it/s, adv_loss=0.472, benign_loss=0.0624, epoch=19]\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "epoch = 20\n",
    "adv_loss_weight = 1.0\n",
    "\n",
    "epsilon = 0.2\n",
    "iter = 20\n",
    "cnn_pgd_iter = adv_train_iter_pgd(train_loader, epoch, lr, criterion, epsilon, iter, adv_loss_weight)\n",
    "torch.save(cnn_pgd_iter.state_dict(), 'model/cnn_pgd_iter.pt')\n",
    "# 要跑大概40min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评测模型性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 测试基于FGSM执行迭代对抗训练的CNN的预测质量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s, test_acc=0.983]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 55.77it/s, test_acc=0.986]\n"
     ]
    }
   ],
   "source": [
    "evaluate_dataloader(test_loader, cnn_fgsm_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 测试基于PGD执行迭代对抗训练的CNN的预测质量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 58.16it/s, test_acc=0.983]\n"
     ]
    }
   ],
   "source": [
    "evaluate_dataloader(test_loader, cnn_pgd_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评测防御效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Week567_img_label.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    imgs, labels = data['img'], data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 评测基于FGSM执行迭代对抗训练的模型针对FGSM/PGD攻击的防御效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For FGSM Iterative.\n",
      "\n",
      "Against FGSM:\n",
      "match rate: 0.85\n",
      "Against PGD:\n",
      "match rate: 0.55\n"
     ]
    }
   ],
   "source": [
    "print(\"For FGSM Iterative.\\n\")\n",
    "print(\"Against FGSM:\")\n",
    "epsilon = 0.2\n",
    "\n",
    "adv_xs = fgsm(imgs, epsilon, cnn_fgsm_iter, criterion, labels)\n",
    "pred_label = evaluate(adv_xs, labels, cnn_fgsm_iter)\n",
    "\n",
    "\n",
    "print(\"Against PGD:\")\n",
    "alpha = 0.07\n",
    "iter = 30\n",
    "\n",
    "adv_xs = pgd(imgs, epsilon,iter, cnn_fgsm_iter, criterion, labels)\n",
    "\n",
    "pred_label = evaluate(adv_xs, labels, cnn_fgsm_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 评测基于PGD执行迭代对抗训练的模型针对FGSM/PGD攻击的防御效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For PGD Iterative.\n",
      "\n",
      "Against FGSM:\n",
      "match rate: 0.85\n",
      "Against PGD:\n",
      "match rate: 0.85\n"
     ]
    }
   ],
   "source": [
    "print(\"For PGD Iterative.\\n\")\n",
    "print(\"Against FGSM:\")\n",
    "epsilon = 0.2\n",
    "\n",
    "adv_xs = fgsm(imgs, epsilon, cnn_pgd_iter, criterion, labels)\n",
    "pred_label = evaluate(adv_xs, labels, cnn_pgd_iter)\n",
    "\n",
    "\n",
    "print(\"Against PGD:\")\n",
    "alpha = 0.07\n",
    "iter = 30\n",
    "\n",
    "adv_xs = pgd(imgs, epsilon, iter, cnn_pgd_iter, criterion, labels)\n",
    "\n",
    "pred_label = evaluate(adv_xs, labels, cnn_pgd_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "0af82aca95c4c45fbffe75f913fb6ef834a764cc29274537834de14d8772671d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
