{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae0986c",
   "metadata": {},
   "source": [
    "# 导入numpy计算库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a40bc0-aa90-41a9-9c16-4acfeba8c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfca513",
   "metadata": {},
   "source": [
    "# 任务1：实现线性模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b3d62",
   "metadata": {},
   "source": [
    "## 1.1 Softmax计算\n",
    "\n",
    "- 输入x：一个K维的向量\n",
    "- 输出o：一个K维的向量\n",
    "- 计算过程\n",
    "    - $o = \\exp(x)$ 这是一个向量\n",
    "    - $sum\\_o = \\text{sum}(o)$ 这是一个标量\n",
    "    - $o = \\frac{o}{sum\\_o}$\n",
    "- 使用的函数请参考文档，包括np.exp、np.sum等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37a30ba-8d2a-45fc-a385-cada130f1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # TODO: 计算输入Numpy向量x的softmax函数计算结果\n",
    "    o = np.exp(x)\n",
    "    o = o / np.sum(o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c994fab",
   "metadata": {},
   "source": [
    "## 1.2 验证softmax模块\n",
    "\n",
    "输出结果大致为$[0.032,  0.087,  0.237,  0.644]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e460ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0320586  0.08714432 0.23688282 0.64391426]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "o = softmax(x)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9122e0",
   "metadata": {},
   "source": [
    "## 1.3 模型正向预测\n",
    "- 输入x：一个K维的向量\n",
    "- 输入weight：一个N * K维的矩阵\n",
    "- 输入bias：一个N维的向量\n",
    "- 输出o：一个N维的概率向量\n",
    "- 计算过程：\n",
    "    - 利用线性模型得到输出\n",
    "    - 用你实现的softmax对输出进行处理，得到概率向量\n",
    "    \n",
    "可能用到np.matmul等函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1194c55-5ed5-4789-8bac-51888bbe1354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, weight, bias):\n",
    "    # TODO: 给定模型参数，计算模型预测结果o，并返回概率向量\n",
    "    o = softmax(np.matmul(weight, np.transpose(x)) + bias)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e3b41",
   "metadata": {},
   "source": [
    "## 1.4 验证正向预测过程\n",
    "\n",
    "输出结果大致为[9.11e-04 9.99e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6fc403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.11051194e-04 9.99088949e-01]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([1, 2])\n",
    "x = np.array([1, 2])\n",
    "y = forward(x, w, b)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a7e0c",
   "metadata": {},
   "source": [
    "# 任务2：计算损失函数\n",
    "- 输入y：一个整数，表示真实标签\n",
    "- 输入o：一个N维向量，表示模型的预测概率（已经经过softmax处理了的模型输出结果）\n",
    "- 输出loss：一个实数，表示损失函数的计算结果\n",
    "\n",
    "这里可能用到np.log等函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de075af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y, o):\n",
    "    label_num = o.shape[0]\n",
    "    y_onehot = np.zeros(label_num)\n",
    "    # TODO: 把y转换到y_onehot上，然后基于模型的输出o计算交叉熵loss\n",
    "    y_onehot[y] = 1\n",
    "    loss = np.sum(-y_onehot*np.log(o))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217daece",
   "metadata": {},
   "source": [
    "## 验证损失函数计算\n",
    "输出结果大致为0.6931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e710402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "y = 0\n",
    "o = np.array([0.5, 0.25, 0.25])\n",
    "print(cross_entropy_loss(y, o))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82142e19",
   "metadata": {},
   "source": [
    "# 任务3：实现梯度计算过程\n",
    "\n",
    "- 输入x：一个K维的向量\n",
    "- 输入o：一个N维的向量\n",
    "- 输入y：一个整数的标签\n",
    "- 输入weight：一个N * K维的矩阵\n",
    "- 输入bias：一个N维的向量\n",
    "- 输出weight_grad：一个N * K维的矩阵，是由loss计算到的weight的梯度\n",
    "- 输出bias_grad：一个N维的向量，是由loss计算到的bias的梯度\n",
    "\n",
    "这里可能会用到np.outer函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af72f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(x, o, y, weight, bias):\n",
    "    label_num = o.shape[0]\n",
    "    y_onehot = np.zeros(label_num)\n",
    "    \n",
    "    # TODO: 把y变成one-hot向量，然后利用PPT中的公式计算模型参数的梯度\n",
    "    y_onehot[y] = 1\n",
    "    weight_grad = np.outer(o - y_onehot, x)\n",
    "    bias_grad = o - y_onehot\n",
    "\n",
    "    \n",
    "    \n",
    "    return weight_grad, bias_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21702b09",
   "metadata": {},
   "source": [
    "## 验证梯度计算公式\n",
    "\n",
    "输出结果大致为(array([[ 0.00091105,  0.0018221 ],\n",
    "       [-0.00091105, -0.0018221 ]]), array([ 0.00091105, -0.00091105]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a5b6a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.00091105,  0.0018221 ],\n",
      "       [-0.00091105, -0.0018221 ]]), array([ 0.00091105, -0.00091105]))\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([1, 2])\n",
    "x = np.array([1, 2])\n",
    "y = 1\n",
    "o = forward(x, w, b)\n",
    "print(backward(x, o, y, w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9ff4de",
   "metadata": {},
   "source": [
    "# 任务4：模型训练\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ca130e",
   "metadata": {},
   "source": [
    "## 准备步骤\n",
    "\n",
    "加载数据，初始化模型参数，定义关键变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdac14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_num = 3\n",
    "input_size = 13\n",
    "\n",
    "epoches = 1000\n",
    "learning_rate = 0.002\n",
    "\n",
    "trainset = np.load(\"trainset.npy\", allow_pickle=True)\n",
    "testset = np.load(\"testset.npy\", allow_pickle=True)\n",
    "\n",
    "weight = np.random.uniform(-0.1, 0.1, (label_num, input_size))\n",
    "bias = np.random.uniform(-0.1, 0.1, label_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e350d",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "如果上述三个模块实现正确，loss将越来越小、逐渐收敛。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1135fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1, averaged loss=1.120\n",
      "epoch=2, averaged loss=1.091\n",
      "epoch=3, averaged loss=1.067\n",
      "epoch=4, averaged loss=1.046\n",
      "epoch=5, averaged loss=1.027\n",
      "epoch=6, averaged loss=1.008\n",
      "epoch=7, averaged loss=0.991\n",
      "epoch=8, averaged loss=0.974\n",
      "epoch=9, averaged loss=0.957\n",
      "epoch=10, averaged loss=0.941\n",
      "epoch=11, averaged loss=0.926\n",
      "epoch=12, averaged loss=0.911\n",
      "epoch=13, averaged loss=0.896\n",
      "epoch=14, averaged loss=0.882\n",
      "epoch=15, averaged loss=0.868\n",
      "epoch=16, averaged loss=0.855\n",
      "epoch=17, averaged loss=0.841\n",
      "epoch=18, averaged loss=0.829\n",
      "epoch=19, averaged loss=0.816\n",
      "epoch=20, averaged loss=0.804\n",
      "epoch=21, averaged loss=0.793\n",
      "epoch=22, averaged loss=0.781\n",
      "epoch=23, averaged loss=0.770\n",
      "epoch=24, averaged loss=0.760\n",
      "epoch=25, averaged loss=0.749\n",
      "epoch=26, averaged loss=0.739\n",
      "epoch=27, averaged loss=0.729\n",
      "epoch=28, averaged loss=0.720\n",
      "epoch=29, averaged loss=0.710\n",
      "epoch=30, averaged loss=0.701\n",
      "epoch=31, averaged loss=0.692\n",
      "epoch=32, averaged loss=0.684\n",
      "epoch=33, averaged loss=0.675\n",
      "epoch=34, averaged loss=0.667\n",
      "epoch=35, averaged loss=0.659\n",
      "epoch=36, averaged loss=0.651\n",
      "epoch=37, averaged loss=0.644\n",
      "epoch=38, averaged loss=0.636\n",
      "epoch=39, averaged loss=0.629\n",
      "epoch=40, averaged loss=0.622\n",
      "epoch=41, averaged loss=0.615\n",
      "epoch=42, averaged loss=0.608\n",
      "epoch=43, averaged loss=0.602\n",
      "epoch=44, averaged loss=0.595\n",
      "epoch=45, averaged loss=0.589\n",
      "epoch=46, averaged loss=0.583\n",
      "epoch=47, averaged loss=0.577\n",
      "epoch=48, averaged loss=0.571\n",
      "epoch=49, averaged loss=0.565\n",
      "epoch=50, averaged loss=0.560\n",
      "epoch=51, averaged loss=0.554\n",
      "epoch=52, averaged loss=0.549\n",
      "epoch=53, averaged loss=0.544\n",
      "epoch=54, averaged loss=0.539\n",
      "epoch=55, averaged loss=0.534\n",
      "epoch=56, averaged loss=0.529\n",
      "epoch=57, averaged loss=0.524\n",
      "epoch=58, averaged loss=0.519\n",
      "epoch=59, averaged loss=0.515\n",
      "epoch=60, averaged loss=0.510\n",
      "epoch=61, averaged loss=0.506\n",
      "epoch=62, averaged loss=0.501\n",
      "epoch=63, averaged loss=0.497\n",
      "epoch=64, averaged loss=0.493\n",
      "epoch=65, averaged loss=0.489\n",
      "epoch=66, averaged loss=0.485\n",
      "epoch=67, averaged loss=0.481\n",
      "epoch=68, averaged loss=0.477\n",
      "epoch=69, averaged loss=0.473\n",
      "epoch=70, averaged loss=0.470\n",
      "epoch=71, averaged loss=0.466\n",
      "epoch=72, averaged loss=0.462\n",
      "epoch=73, averaged loss=0.459\n",
      "epoch=74, averaged loss=0.456\n",
      "epoch=75, averaged loss=0.452\n",
      "epoch=76, averaged loss=0.449\n",
      "epoch=77, averaged loss=0.446\n",
      "epoch=78, averaged loss=0.442\n",
      "epoch=79, averaged loss=0.439\n",
      "epoch=80, averaged loss=0.436\n",
      "epoch=81, averaged loss=0.433\n",
      "epoch=82, averaged loss=0.430\n",
      "epoch=83, averaged loss=0.427\n",
      "epoch=84, averaged loss=0.424\n",
      "epoch=85, averaged loss=0.421\n",
      "epoch=86, averaged loss=0.419\n",
      "epoch=87, averaged loss=0.416\n",
      "epoch=88, averaged loss=0.413\n",
      "epoch=89, averaged loss=0.411\n",
      "epoch=90, averaged loss=0.408\n",
      "epoch=91, averaged loss=0.405\n",
      "epoch=92, averaged loss=0.403\n",
      "epoch=93, averaged loss=0.400\n",
      "epoch=94, averaged loss=0.398\n",
      "epoch=95, averaged loss=0.395\n",
      "epoch=96, averaged loss=0.393\n",
      "epoch=97, averaged loss=0.391\n",
      "epoch=98, averaged loss=0.388\n",
      "epoch=99, averaged loss=0.386\n",
      "epoch=100, averaged loss=0.384\n",
      "epoch=101, averaged loss=0.382\n",
      "epoch=102, averaged loss=0.379\n",
      "epoch=103, averaged loss=0.377\n",
      "epoch=104, averaged loss=0.375\n",
      "epoch=105, averaged loss=0.373\n",
      "epoch=106, averaged loss=0.371\n",
      "epoch=107, averaged loss=0.369\n",
      "epoch=108, averaged loss=0.367\n",
      "epoch=109, averaged loss=0.365\n",
      "epoch=110, averaged loss=0.363\n",
      "epoch=111, averaged loss=0.361\n",
      "epoch=112, averaged loss=0.359\n",
      "epoch=113, averaged loss=0.357\n",
      "epoch=114, averaged loss=0.355\n",
      "epoch=115, averaged loss=0.354\n",
      "epoch=116, averaged loss=0.352\n",
      "epoch=117, averaged loss=0.350\n",
      "epoch=118, averaged loss=0.348\n",
      "epoch=119, averaged loss=0.347\n",
      "epoch=120, averaged loss=0.345\n",
      "epoch=121, averaged loss=0.343\n",
      "epoch=122, averaged loss=0.341\n",
      "epoch=123, averaged loss=0.340\n",
      "epoch=124, averaged loss=0.338\n",
      "epoch=125, averaged loss=0.337\n",
      "epoch=126, averaged loss=0.335\n",
      "epoch=127, averaged loss=0.333\n",
      "epoch=128, averaged loss=0.332\n",
      "epoch=129, averaged loss=0.330\n",
      "epoch=130, averaged loss=0.329\n",
      "epoch=131, averaged loss=0.327\n",
      "epoch=132, averaged loss=0.326\n",
      "epoch=133, averaged loss=0.324\n",
      "epoch=134, averaged loss=0.323\n",
      "epoch=135, averaged loss=0.322\n",
      "epoch=136, averaged loss=0.320\n",
      "epoch=137, averaged loss=0.319\n",
      "epoch=138, averaged loss=0.317\n",
      "epoch=139, averaged loss=0.316\n",
      "epoch=140, averaged loss=0.315\n",
      "epoch=141, averaged loss=0.313\n",
      "epoch=142, averaged loss=0.312\n",
      "epoch=143, averaged loss=0.311\n",
      "epoch=144, averaged loss=0.309\n",
      "epoch=145, averaged loss=0.308\n",
      "epoch=146, averaged loss=0.307\n",
      "epoch=147, averaged loss=0.306\n",
      "epoch=148, averaged loss=0.304\n",
      "epoch=149, averaged loss=0.303\n",
      "epoch=150, averaged loss=0.302\n",
      "epoch=151, averaged loss=0.301\n",
      "epoch=152, averaged loss=0.300\n",
      "epoch=153, averaged loss=0.298\n",
      "epoch=154, averaged loss=0.297\n",
      "epoch=155, averaged loss=0.296\n",
      "epoch=156, averaged loss=0.295\n",
      "epoch=157, averaged loss=0.294\n",
      "epoch=158, averaged loss=0.293\n",
      "epoch=159, averaged loss=0.292\n",
      "epoch=160, averaged loss=0.290\n",
      "epoch=161, averaged loss=0.289\n",
      "epoch=162, averaged loss=0.288\n",
      "epoch=163, averaged loss=0.287\n",
      "epoch=164, averaged loss=0.286\n",
      "epoch=165, averaged loss=0.285\n",
      "epoch=166, averaged loss=0.284\n",
      "epoch=167, averaged loss=0.283\n",
      "epoch=168, averaged loss=0.282\n",
      "epoch=169, averaged loss=0.281\n",
      "epoch=170, averaged loss=0.280\n",
      "epoch=171, averaged loss=0.279\n",
      "epoch=172, averaged loss=0.278\n",
      "epoch=173, averaged loss=0.277\n",
      "epoch=174, averaged loss=0.276\n",
      "epoch=175, averaged loss=0.275\n",
      "epoch=176, averaged loss=0.274\n",
      "epoch=177, averaged loss=0.273\n",
      "epoch=178, averaged loss=0.272\n",
      "epoch=179, averaged loss=0.272\n",
      "epoch=180, averaged loss=0.271\n",
      "epoch=181, averaged loss=0.270\n",
      "epoch=182, averaged loss=0.269"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=183, averaged loss=0.268\n",
      "epoch=184, averaged loss=0.267\n",
      "epoch=185, averaged loss=0.266\n",
      "epoch=186, averaged loss=0.265\n",
      "epoch=187, averaged loss=0.265\n",
      "epoch=188, averaged loss=0.264\n",
      "epoch=189, averaged loss=0.263\n",
      "epoch=190, averaged loss=0.262\n",
      "epoch=191, averaged loss=0.261\n",
      "epoch=192, averaged loss=0.260\n",
      "epoch=193, averaged loss=0.260\n",
      "epoch=194, averaged loss=0.259\n",
      "epoch=195, averaged loss=0.258\n",
      "epoch=196, averaged loss=0.257\n",
      "epoch=197, averaged loss=0.256\n",
      "epoch=198, averaged loss=0.256\n",
      "epoch=199, averaged loss=0.255\n",
      "epoch=200, averaged loss=0.254\n",
      "epoch=201, averaged loss=0.253\n",
      "epoch=202, averaged loss=0.253\n",
      "epoch=203, averaged loss=0.252\n",
      "epoch=204, averaged loss=0.251\n",
      "epoch=205, averaged loss=0.250\n",
      "epoch=206, averaged loss=0.250\n",
      "epoch=207, averaged loss=0.249\n",
      "epoch=208, averaged loss=0.248\n",
      "epoch=209, averaged loss=0.248\n",
      "epoch=210, averaged loss=0.247\n",
      "epoch=211, averaged loss=0.246\n",
      "epoch=212, averaged loss=0.245\n",
      "epoch=213, averaged loss=0.245\n",
      "epoch=214, averaged loss=0.244\n",
      "epoch=215, averaged loss=0.243\n",
      "epoch=216, averaged loss=0.243\n",
      "epoch=217, averaged loss=0.242\n",
      "epoch=218, averaged loss=0.241\n",
      "epoch=219, averaged loss=0.241\n",
      "epoch=220, averaged loss=0.240\n",
      "epoch=221, averaged loss=0.239\n",
      "epoch=222, averaged loss=0.239\n",
      "epoch=223, averaged loss=0.238\n",
      "epoch=224, averaged loss=0.237\n",
      "epoch=225, averaged loss=0.237\n",
      "epoch=226, averaged loss=0.236\n",
      "epoch=227, averaged loss=0.236\n",
      "epoch=228, averaged loss=0.235\n",
      "epoch=229, averaged loss=0.234\n",
      "epoch=230, averaged loss=0.234\n",
      "epoch=231, averaged loss=0.233\n",
      "epoch=232, averaged loss=0.233\n",
      "epoch=233, averaged loss=0.232\n",
      "epoch=234, averaged loss=0.231\n",
      "epoch=235, averaged loss=0.231\n",
      "epoch=236, averaged loss=0.230\n",
      "epoch=237, averaged loss=0.230\n",
      "epoch=238, averaged loss=0.229\n",
      "epoch=239, averaged loss=0.228\n",
      "epoch=240, averaged loss=0.228\n",
      "epoch=241, averaged loss=0.227\n",
      "epoch=242, averaged loss=0.227\n",
      "epoch=243, averaged loss=0.226\n",
      "epoch=244, averaged loss=0.226\n",
      "epoch=245, averaged loss=0.225\n",
      "epoch=246, averaged loss=0.225\n",
      "epoch=247, averaged loss=0.224\n",
      "epoch=248, averaged loss=0.223\n",
      "epoch=249, averaged loss=0.223\n",
      "epoch=250, averaged loss=0.222\n",
      "epoch=251, averaged loss=0.222\n",
      "epoch=252, averaged loss=0.221\n",
      "epoch=253, averaged loss=0.221\n",
      "epoch=254, averaged loss=0.220\n",
      "epoch=255, averaged loss=0.220\n",
      "epoch=256, averaged loss=0.219\n",
      "epoch=257, averaged loss=0.219\n",
      "epoch=258, averaged loss=0.218\n",
      "epoch=259, averaged loss=0.218\n",
      "epoch=260, averaged loss=0.217\n",
      "epoch=261, averaged loss=0.217\n",
      "epoch=262, averaged loss=0.216\n",
      "epoch=263, averaged loss=0.216\n",
      "epoch=264, averaged loss=0.215\n",
      "epoch=265, averaged loss=0.215\n",
      "epoch=266, averaged loss=0.214\n",
      "epoch=267, averaged loss=0.214\n",
      "epoch=268, averaged loss=0.213\n",
      "epoch=269, averaged loss=0.213\n",
      "epoch=270, averaged loss=0.212\n",
      "epoch=271, averaged loss=0.212\n",
      "epoch=272, averaged loss=0.212\n",
      "epoch=273, averaged loss=0.211\n",
      "epoch=274, averaged loss=0.211\n",
      "epoch=275, averaged loss=0.210\n",
      "epoch=276, averaged loss=0.210\n",
      "epoch=277, averaged loss=0.209\n",
      "epoch=278, averaged loss=0.209\n",
      "epoch=279, averaged loss=0.208\n",
      "epoch=280, averaged loss=0.208\n",
      "epoch=281, averaged loss=0.207\n",
      "epoch=282, averaged loss=0.207\n",
      "epoch=283, averaged loss=0.207\n",
      "epoch=284, averaged loss=0.206\n",
      "epoch=285, averaged loss=0.206\n",
      "epoch=286, averaged loss=0.205\n",
      "epoch=287, averaged loss=0.205\n",
      "epoch=288, averaged loss=0.204\n",
      "epoch=289, averaged loss=0.204\n",
      "epoch=290, averaged loss=0.204\n",
      "epoch=291, averaged loss=0.203\n",
      "epoch=292, averaged loss=0.203\n",
      "epoch=293, averaged loss=0.202\n",
      "epoch=294, averaged loss=0.202\n",
      "epoch=295, averaged loss=0.202\n",
      "epoch=296, averaged loss=0.201\n",
      "epoch=297, averaged loss=0.201\n",
      "epoch=298, averaged loss=0.200\n",
      "epoch=299, averaged loss=0.200\n",
      "epoch=300, averaged loss=0.200\n",
      "epoch=301, averaged loss=0.199\n",
      "epoch=302, averaged loss=0.199\n",
      "epoch=303, averaged loss=0.198\n",
      "epoch=304, averaged loss=0.198\n",
      "epoch=305, averaged loss=0.198\n",
      "epoch=306, averaged loss=0.197\n",
      "epoch=307, averaged loss=0.197\n",
      "epoch=308, averaged loss=0.196\n",
      "epoch=309, averaged loss=0.196\n",
      "epoch=310, averaged loss=0.196\n",
      "epoch=311, averaged loss=0.195\n",
      "epoch=312, averaged loss=0.195\n",
      "epoch=313, averaged loss=0.195\n",
      "epoch=314, averaged loss=0.194\n",
      "epoch=315, averaged loss=0.194\n",
      "epoch=316, averaged loss=0.194\n",
      "epoch=317, averaged loss=0.193\n",
      "epoch=318, averaged loss=0.193\n",
      "epoch=319, averaged loss=0.192\n",
      "epoch=320, averaged loss=0.192\n",
      "epoch=321, averaged loss=0.192\n",
      "epoch=322, averaged loss=0.191\n",
      "epoch=323, averaged loss=0.191\n",
      "epoch=324, averaged loss=0.191\n",
      "epoch=325, averaged loss=0.190\n",
      "epoch=326, averaged loss=0.190\n",
      "epoch=327, averaged loss=0.190\n",
      "epoch=328, averaged loss=0.189\n",
      "epoch=329, averaged loss=0.189\n",
      "epoch=330, averaged loss=0.189\n",
      "epoch=331, averaged loss=0.188\n",
      "epoch=332, averaged loss=0.188\n",
      "epoch=333, averaged loss=0.188\n",
      "epoch=334, averaged loss=0.187\n",
      "epoch=335, averaged loss=0.187\n",
      "epoch=336, averaged loss=0.187\n",
      "epoch=337, averaged loss=0.186\n",
      "epoch=338, averaged loss=0.186\n",
      "epoch=339, averaged loss=0.186\n",
      "epoch=340, averaged loss=0.185\n",
      "epoch=341, averaged loss=0.185\n",
      "epoch=342, averaged loss=0.185\n",
      "epoch=343, averaged loss=0.184\n",
      "epoch=344, averaged loss=0.184\n",
      "epoch=345, averaged loss=0.184\n",
      "epoch=346, averaged loss=0.183\n",
      "epoch=347, averaged loss=0.183\n",
      "epoch=348, averaged loss=0.183\n",
      "epoch=349, averaged loss=0.182\n",
      "epoch=350, averaged loss=0.182\n",
      "epoch=351, averaged loss=0.182\n",
      "epoch=352, averaged loss=0.182\n",
      "epoch=353, averaged loss=0.181\n",
      "epoch=354, averaged loss=0.181\n",
      "epoch=355, averaged loss=0.181\n",
      "epoch=356, averaged loss=0.180\n",
      "epoch=357, averaged loss=0.180\n",
      "epoch=358, averaged loss=0.180\n",
      "epoch=359, averaged loss=0.179\n",
      "epoch=360, averaged loss=0.179\n",
      "epoch=361, averaged loss=0.179\n",
      "epoch=362, averaged loss=0.179\n",
      "epoch=363, averaged loss=0.178\n",
      "epoch=364, averaged loss=0.178\n",
      "epoch=365, averaged loss=0.178\n",
      "epoch=366, averaged loss=0.177\n",
      "epoch=367, averaged loss=0.177\n",
      "epoch=368, averaged loss=0.177\n",
      "epoch=369, averaged loss=0.177\n",
      "epoch=370, averaged loss=0.176\n",
      "epoch=371, averaged loss=0.176\n",
      "epoch=372, averaged loss=0.176\n",
      "epoch=373, averaged loss=0.175\n",
      "epoch=374, averaged loss=0.175\n",
      "epoch=375, averaged loss=0.175\n",
      "epoch=376, averaged loss=0.175\n",
      "epoch=377, averaged loss=0.174\n",
      "epoch=378, averaged loss=0.174\n",
      "epoch=379, averaged loss=0.174\n",
      "epoch=380, averaged loss=0.174\n",
      "epoch=381, averaged loss=0.173\n",
      "epoch=382, averaged loss=0.173\n",
      "epoch=383, averaged loss=0.173\n",
      "epoch=384, averaged loss=0.173\n",
      "epoch=385, averaged loss=0.172\n",
      "epoch=386, averaged loss=0.172\n",
      "epoch=387, averaged loss=0.172\n",
      "epoch=388, averaged loss=0.171\n",
      "epoch=389, averaged loss=0.171\n",
      "epoch=390, averaged loss=0.171\n",
      "epoch=391, averaged loss=0.171\n",
      "epoch=392, averaged loss=0.170\n",
      "epoch=393, averaged loss=0.170\n",
      "epoch=394, averaged loss=0.170\n",
      "epoch=395, averaged loss=0.170\n",
      "epoch=396, averaged loss=0.169\n",
      "epoch=397, averaged loss=0.169\n",
      "epoch=398, averaged loss=0.169\n",
      "epoch=399, averaged loss=0.169\n",
      "epoch=400, averaged loss=0.168\n",
      "epoch=401, averaged loss=0.168\n",
      "epoch=402, averaged loss=0.168\n",
      "epoch=403, averaged loss=0.168\n",
      "epoch=404, averaged loss=0.167\n",
      "epoch=405, averaged loss=0.167\n",
      "epoch=406, averaged loss=0.167\n",
      "epoch=407, averaged loss=0.167\n",
      "epoch=408, averaged loss=0.166\n",
      "epoch=409, averaged loss=0.166\n",
      "epoch=410, averaged loss=0.166\n",
      "epoch=411, averaged loss=0.166\n",
      "epoch=412, averaged loss=0.166\n",
      "epoch=413, averaged loss=0.165\n",
      "epoch=414, averaged loss=0.165\n",
      "epoch=415, averaged loss=0.165\n",
      "epoch=416, averaged loss=0.165\n",
      "epoch=417, averaged loss=0.164\n",
      "epoch=418, averaged loss=0.164\n",
      "epoch=419, averaged loss=0.164\n",
      "epoch=420, averaged loss=0.164\n",
      "epoch=421, averaged loss=0.163\n",
      "epoch=422, averaged loss=0.163\n",
      "epoch=423, averaged loss=0.163\n",
      "epoch=424, averaged loss=0.163\n",
      "epoch=425, averaged loss=0.163\n",
      "epoch=426, averaged loss=0.162\n",
      "epoch=427, averaged loss=0.162\n",
      "epoch=428, averaged loss=0.162\n",
      "epoch=429, averaged loss=0.162\n",
      "epoch=430, averaged loss=0.161\n",
      "epoch=431, averaged loss=0.161\n",
      "epoch=432, averaged loss=0.161\n",
      "epoch=433, averaged loss=0.161\n",
      "epoch=434, averaged loss=0.161\n",
      "epoch=435, averaged loss=0.160\n",
      "epoch=436, averaged loss=0.160\n",
      "epoch=437, averaged loss=0.160\n",
      "epoch=438, averaged loss=0.160\n",
      "epoch=439, averaged loss=0.159\n",
      "epoch=440, averaged loss=0.159\n",
      "epoch=441, averaged loss=0.159\n",
      "epoch=442, averaged loss=0.159\n",
      "epoch=443, averaged loss=0.159\n",
      "epoch=444, averaged loss=0.158\n",
      "epoch=445, averaged loss=0.158\n",
      "epoch=446, averaged loss=0.158\n",
      "epoch=447, averaged loss=0.158\n",
      "epoch=448, averaged loss=0.158\n",
      "epoch=449, averaged loss=0.157\n",
      "epoch=450, averaged loss=0.157\n",
      "epoch=451, averaged loss=0.157\n",
      "epoch=452, averaged loss=0.157\n",
      "epoch=453, averaged loss=0.157\n",
      "epoch=454, averaged loss=0.156\n",
      "epoch=455, averaged loss=0.156\n",
      "epoch=456, averaged loss=0.156\n",
      "epoch=457, averaged loss=0.156\n",
      "epoch=458, averaged loss=0.156\n",
      "epoch=459, averaged loss=0.155\n",
      "epoch=460, averaged loss=0.155\n",
      "epoch=461, averaged loss=0.155\n",
      "epoch=462, averaged loss=0.155\n",
      "epoch=463, averaged loss=0.155\n",
      "epoch=464, averaged loss=0.154\n",
      "epoch=465, averaged loss=0.154\n",
      "epoch=466, averaged loss=0.154\n",
      "epoch=467, averaged loss=0.154\n",
      "epoch=468, averaged loss=0.154\n",
      "epoch=469, averaged loss=0.153\n",
      "epoch=470, averaged loss=0.153\n",
      "epoch=471, averaged loss=0.153\n",
      "epoch=472, averaged loss=0.153\n",
      "epoch=473, averaged loss=0.153\n",
      "epoch=474, averaged loss=0.152\n",
      "epoch=475, averaged loss=0.152\n",
      "epoch=476, averaged loss=0.152\n",
      "epoch=477, averaged loss=0.152\n",
      "epoch=478, averaged loss=0.152\n",
      "epoch=479, averaged loss=0.152\n",
      "epoch=480, averaged loss=0.151\n",
      "epoch=481, averaged loss=0.151\n",
      "epoch=482, averaged loss=0.151\n",
      "epoch=483, averaged loss=0.151\n",
      "epoch=484, averaged loss=0.151\n",
      "epoch=485, averaged loss=0.150\n",
      "epoch=486, averaged loss=0.150\n",
      "epoch=487, averaged loss=0.150\n",
      "epoch=488, averaged loss=0.150\n",
      "epoch=489, averaged loss=0.150\n",
      "epoch=490, averaged loss=0.150\n",
      "epoch=491, averaged loss=0.149\n",
      "epoch=492, averaged loss=0.149\n",
      "epoch=493, averaged loss=0.149\n",
      "epoch=494, averaged loss=0.149\n",
      "epoch=495, averaged loss=0.149\n",
      "epoch=496, averaged loss=0.149\n",
      "epoch=497, averaged loss=0.148\n",
      "epoch=498, averaged loss=0.148\n",
      "epoch=499, averaged loss=0.148\n",
      "epoch=500, averaged loss=0.148\n",
      "epoch=501, averaged loss=0.148\n",
      "epoch=502, averaged loss=0.147\n",
      "epoch=503, averaged loss=0.147\n",
      "epoch=504, averaged loss=0.147\n",
      "epoch=505, averaged loss=0.147\n",
      "epoch=506, averaged loss=0.147\n",
      "epoch=507, averaged loss=0.147\n",
      "epoch=508, averaged loss=0.146\n",
      "epoch=509, averaged loss=0.146\n",
      "epoch=510, averaged loss=0.146\n",
      "epoch=511, averaged loss=0.146\n",
      "epoch=512, averaged loss=0.146\n",
      "epoch=513, averaged loss=0.146\n",
      "epoch=514, averaged loss=0.145\n",
      "epoch=515, averaged loss=0.145\n",
      "epoch=516, averaged loss=0.145\n",
      "epoch=517, averaged loss=0.145\n",
      "epoch=518, averaged loss=0.145\n",
      "epoch=519, averaged loss=0.145\n",
      "epoch=520, averaged loss=0.144\n",
      "epoch=521, averaged loss=0.144\n",
      "epoch=522, averaged loss=0.144\n",
      "epoch=523, averaged loss=0.144\n",
      "epoch=524, averaged loss=0.144\n",
      "epoch=525, averaged loss=0.144\n",
      "epoch=526, averaged loss=0.144\n",
      "epoch=527, averaged loss=0.143\n",
      "epoch=528, averaged loss=0.143\n",
      "epoch=529, averaged loss=0.143\n",
      "epoch=530, averaged loss=0.143\n",
      "epoch=531, averaged loss=0.143\n",
      "epoch=532, averaged loss=0.143\n",
      "epoch=533, averaged loss=0.142\n",
      "epoch=534, averaged loss=0.142\n",
      "epoch=535, averaged loss=0.142\n",
      "epoch=536, averaged loss=0.142\n",
      "epoch=537, averaged loss=0.142\n",
      "epoch=538, averaged loss=0.142\n",
      "epoch=539, averaged loss=0.141\n",
      "epoch=540, averaged loss=0.141\n",
      "epoch=541, averaged loss=0.141\n",
      "epoch=542, averaged loss=0.141\n",
      "epoch=543, averaged loss=0.141\n",
      "epoch=544, averaged loss=0.141\n",
      "epoch=545, averaged loss=0.141\n",
      "epoch=546, averaged loss=0.140\n",
      "epoch=547, averaged loss=0.140\n",
      "epoch=548, averaged loss=0.140\n",
      "epoch=549, averaged loss=0.140\n",
      "epoch=550, averaged loss=0.140\n",
      "epoch=551, averaged loss=0.140\n",
      "epoch=552, averaged loss=0.140\n",
      "epoch=553, averaged loss=0.139\n",
      "epoch=554, averaged loss=0.139\n",
      "epoch=555, averaged loss=0.139\n",
      "epoch=556, averaged loss=0.139\n",
      "epoch=557, averaged loss=0.139\n",
      "epoch=558, averaged loss=0.139\n",
      "epoch=559, averaged loss=0.139\n",
      "epoch=560, averaged loss=0.138\n",
      "epoch=561, averaged loss=0.138\n",
      "epoch=562, averaged loss=0.138\n",
      "epoch=563, averaged loss=0.138\n",
      "epoch=564, averaged loss=0.138\n",
      "epoch=565, averaged loss=0.138\n",
      "epoch=566, averaged loss=0.138\n",
      "epoch=567, averaged loss=0.137\n",
      "epoch=568, averaged loss=0.137\n",
      "epoch=569, averaged loss=0.137\n",
      "epoch=570, averaged loss=0.137\n",
      "epoch=571, averaged loss=0.137\n",
      "epoch=572, averaged loss=0.137\n",
      "epoch=573, averaged loss=0.137\n",
      "epoch=574, averaged loss=0.136\n",
      "epoch=575, averaged loss=0.136\n",
      "epoch=576, averaged loss=0.136\n",
      "epoch=577, averaged loss=0.136\n",
      "epoch=578, averaged loss=0.136\n",
      "epoch=579, averaged loss=0.136\n",
      "epoch=580, averaged loss=0.136\n",
      "epoch=581, averaged loss=0.135\n",
      "epoch=582, averaged loss=0.135\n",
      "epoch=583, averaged loss=0.135\n",
      "epoch=584, averaged loss=0.135\n",
      "epoch=585, averaged loss=0.135\n",
      "epoch=586, averaged loss=0.135\n",
      "epoch=587, averaged loss=0.135\n",
      "epoch=588, averaged loss=0.134\n",
      "epoch=589, averaged loss=0.134\n",
      "epoch=590, averaged loss=0.134\n",
      "epoch=591, averaged loss=0.134\n",
      "epoch=592, averaged loss=0.134\n",
      "epoch=593, averaged loss=0.134\n",
      "epoch=594, averaged loss=0.134\n",
      "epoch=595, averaged loss=0.134\n",
      "epoch=596, averaged loss=0.133\n",
      "epoch=597, averaged loss=0.133\n",
      "epoch=598, averaged loss=0.133\n",
      "epoch=599, averaged loss=0.133\n",
      "epoch=600, averaged loss=0.133\n",
      "epoch=601, averaged loss=0.133\n",
      "epoch=602, averaged loss=0.133\n",
      "epoch=603, averaged loss=0.133\n",
      "epoch=604, averaged loss=0.132\n",
      "epoch=605, averaged loss=0.132\n",
      "epoch=606, averaged loss=0.132\n",
      "epoch=607, averaged loss=0.132\n",
      "epoch=608, averaged loss=0.132\n",
      "epoch=609, averaged loss=0.132\n",
      "epoch=610, averaged loss=0.132\n",
      "epoch=611, averaged loss=0.132\n",
      "epoch=612, averaged loss=0.131\n",
      "epoch=613, averaged loss=0.131\n",
      "epoch=614, averaged loss=0.131\n",
      "epoch=615, averaged loss=0.131\n",
      "epoch=616, averaged loss=0.131\n",
      "epoch=617, averaged loss=0.131\n",
      "epoch=618, averaged loss=0.131\n",
      "epoch=619, averaged loss=0.131\n",
      "epoch=620, averaged loss=0.130\n",
      "epoch=621, averaged loss=0.130\n",
      "epoch=622, averaged loss=0.130\n",
      "epoch=623, averaged loss=0.130\n",
      "epoch=624, averaged loss=0.130\n",
      "epoch=625, averaged loss=0.130\n",
      "epoch=626, averaged loss=0.130\n",
      "epoch=627, averaged loss=0.130\n",
      "epoch=628, averaged loss=0.129\n",
      "epoch=629, averaged loss=0.129\n",
      "epoch=630, averaged loss=0.129\n",
      "epoch=631, averaged loss=0.129\n",
      "epoch=632, averaged loss=0.129\n",
      "epoch=633, averaged loss=0.129\n",
      "epoch=634, averaged loss=0.129\n",
      "epoch=635, averaged loss=0.129\n",
      "epoch=636, averaged loss=0.128\n",
      "epoch=637, averaged loss=0.128\n",
      "epoch=638, averaged loss=0.128\n",
      "epoch=639, averaged loss=0.128\n",
      "epoch=640, averaged loss=0.128\n",
      "epoch=641, averaged loss=0.128\n",
      "epoch=642, averaged loss=0.128\n",
      "epoch=643, averaged loss=0.128\n",
      "epoch=644, averaged loss=0.128\n",
      "epoch=645, averaged loss=0.127\n",
      "epoch=646, averaged loss=0.127\n",
      "epoch=647, averaged loss=0.127\n",
      "epoch=648, averaged loss=0.127\n",
      "epoch=649, averaged loss=0.127\n",
      "epoch=650, averaged loss=0.127\n",
      "epoch=651, averaged loss=0.127\n",
      "epoch=652, averaged loss=0.127\n",
      "epoch=653, averaged loss=0.127\n",
      "epoch=654, averaged loss=0.126\n",
      "epoch=655, averaged loss=0.126\n",
      "epoch=656, averaged loss=0.126\n",
      "epoch=657, averaged loss=0.126\n",
      "epoch=658, averaged loss=0.126\n",
      "epoch=659, averaged loss=0.126\n",
      "epoch=660, averaged loss=0.126\n",
      "epoch=661, averaged loss=0.126\n",
      "epoch=662, averaged loss=0.126\n",
      "epoch=663, averaged loss=0.125\n",
      "epoch=664, averaged loss=0.125\n",
      "epoch=665, averaged loss=0.125\n",
      "epoch=666, averaged loss=0.125\n",
      "epoch=667, averaged loss=0.125\n",
      "epoch=668, averaged loss=0.125\n",
      "epoch=669, averaged loss=0.125\n",
      "epoch=670, averaged loss=0.125\n",
      "epoch=671, averaged loss=0.125\n",
      "epoch=672, averaged loss=0.124\n",
      "epoch=673, averaged loss=0.124\n",
      "epoch=674, averaged loss=0.124\n",
      "epoch=675, averaged loss=0.124\n",
      "epoch=676, averaged loss=0.124\n",
      "epoch=677, averaged loss=0.124\n",
      "epoch=678, averaged loss=0.124\n",
      "epoch=679, averaged loss=0.124\n",
      "epoch=680, averaged loss=0.124\n",
      "epoch=681, averaged loss=0.123\n",
      "epoch=682, averaged loss=0.123\n",
      "epoch=683, averaged loss=0.123\n",
      "epoch=684, averaged loss=0.123\n",
      "epoch=685, averaged loss=0.123\n",
      "epoch=686, averaged loss=0.123\n",
      "epoch=687, averaged loss=0.123\n",
      "epoch=688, averaged loss=0.123\n",
      "epoch=689, averaged loss=0.123\n",
      "epoch=690, averaged loss=0.123\n",
      "epoch=691, averaged loss=0.122\n",
      "epoch=692, averaged loss=0.122\n",
      "epoch=693, averaged loss=0.122\n",
      "epoch=694, averaged loss=0.122\n",
      "epoch=695, averaged loss=0.122\n",
      "epoch=696, averaged loss=0.122\n",
      "epoch=697, averaged loss=0.122\n",
      "epoch=698, averaged loss=0.122\n",
      "epoch=699, averaged loss=0.122\n",
      "epoch=700, averaged loss=0.122\n",
      "epoch=701, averaged loss=0.121\n",
      "epoch=702, averaged loss=0.121\n",
      "epoch=703, averaged loss=0.121\n",
      "epoch=704, averaged loss=0.121\n",
      "epoch=705, averaged loss=0.121\n",
      "epoch=706, averaged loss=0.121\n",
      "epoch=707, averaged loss=0.121\n",
      "epoch=708, averaged loss=0.121\n",
      "epoch=709, averaged loss=0.121\n",
      "epoch=710, averaged loss=0.121\n",
      "epoch=711, averaged loss=0.120\n",
      "epoch=712, averaged loss=0.120\n",
      "epoch=713, averaged loss=0.120\n",
      "epoch=714, averaged loss=0.120\n",
      "epoch=715, averaged loss=0.120\n",
      "epoch=716, averaged loss=0.120\n",
      "epoch=717, averaged loss=0.120\n",
      "epoch=718, averaged loss=0.120\n",
      "epoch=719, averaged loss=0.120\n",
      "epoch=720, averaged loss=0.120\n",
      "epoch=721, averaged loss=0.119\n",
      "epoch=722, averaged loss=0.119\n",
      "epoch=723, averaged loss=0.119\n",
      "epoch=724, averaged loss=0.119\n",
      "epoch=725, averaged loss=0.119\n",
      "epoch=726, averaged loss=0.119\n",
      "epoch=727, averaged loss=0.119\n",
      "epoch=728, averaged loss=0.119\n",
      "epoch=729, averaged loss=0.119\n",
      "epoch=730, averaged loss=0.119\n",
      "epoch=731, averaged loss=0.119\n",
      "epoch=732, averaged loss=0.118\n",
      "epoch=733, averaged loss=0.118\n",
      "epoch=734, averaged loss=0.118\n",
      "epoch=735, averaged loss=0.118\n",
      "epoch=736, averaged loss=0.118\n",
      "epoch=737, averaged loss=0.118\n",
      "epoch=738, averaged loss=0.118\n",
      "epoch=739, averaged loss=0.118\n",
      "epoch=740, averaged loss=0.118\n",
      "epoch=741, averaged loss=0.118\n",
      "epoch=742, averaged loss=0.117\n",
      "epoch=743, averaged loss=0.117\n",
      "epoch=744, averaged loss=0.117\n",
      "epoch=745, averaged loss=0.117\n",
      "epoch=746, averaged loss=0.117\n",
      "epoch=747, averaged loss=0.117\n",
      "epoch=748, averaged loss=0.117\n",
      "epoch=749, averaged loss=0.117\n",
      "epoch=750, averaged loss=0.117\n",
      "epoch=751, averaged loss=0.117\n",
      "epoch=752, averaged loss=0.117\n",
      "epoch=753, averaged loss=0.116\n",
      "epoch=754, averaged loss=0.116\n",
      "epoch=755, averaged loss=0.116\n",
      "epoch=756, averaged loss=0.116\n",
      "epoch=757, averaged loss=0.116\n",
      "epoch=758, averaged loss=0.116\n",
      "epoch=759, averaged loss=0.116\n",
      "epoch=760, averaged loss=0.116\n",
      "epoch=761, averaged loss=0.116\n",
      "epoch=762, averaged loss=0.116\n",
      "epoch=763, averaged loss=0.116\n",
      "epoch=764, averaged loss=0.116\n",
      "epoch=765, averaged loss=0.115\n",
      "epoch=766, averaged loss=0.115\n",
      "epoch=767, averaged loss=0.115\n",
      "epoch=768, averaged loss=0.115\n",
      "epoch=769, averaged loss=0.115\n",
      "epoch=770, averaged loss=0.115\n",
      "epoch=771, averaged loss=0.115\n",
      "epoch=772, averaged loss=0.115\n",
      "epoch=773, averaged loss=0.115\n",
      "epoch=774, averaged loss=0.115\n",
      "epoch=775, averaged loss=0.115\n",
      "epoch=776, averaged loss=0.114\n",
      "epoch=777, averaged loss=0.114\n",
      "epoch=778, averaged loss=0.114\n",
      "epoch=779, averaged loss=0.114\n",
      "epoch=780, averaged loss=0.114\n",
      "epoch=781, averaged loss=0.114\n",
      "epoch=782, averaged loss=0.114\n",
      "epoch=783, averaged loss=0.114\n",
      "epoch=784, averaged loss=0.114\n",
      "epoch=785, averaged loss=0.114\n",
      "epoch=786, averaged loss=0.114\n",
      "epoch=787, averaged loss=0.114\n",
      "epoch=788, averaged loss=0.113\n",
      "epoch=789, averaged loss=0.113\n",
      "epoch=790, averaged loss=0.113\n",
      "epoch=791, averaged loss=0.113\n",
      "epoch=792, averaged loss=0.113\n",
      "epoch=793, averaged loss=0.113\n",
      "epoch=794, averaged loss=0.113\n",
      "epoch=795, averaged loss=0.113\n",
      "epoch=796, averaged loss=0.113\n",
      "epoch=797, averaged loss=0.113\n",
      "epoch=798, averaged loss=0.113\n",
      "epoch=799, averaged loss=0.113\n",
      "epoch=800, averaged loss=0.112\n",
      "epoch=801, averaged loss=0.112\n",
      "epoch=802, averaged loss=0.112\n",
      "epoch=803, averaged loss=0.112\n",
      "epoch=804, averaged loss=0.112\n",
      "epoch=805, averaged loss=0.112\n",
      "epoch=806, averaged loss=0.112\n",
      "epoch=807, averaged loss=0.112\n",
      "epoch=808, averaged loss=0.112\n",
      "epoch=809, averaged loss=0.112\n",
      "epoch=810, averaged loss=0.112\n",
      "epoch=811, averaged loss=0.112\n",
      "epoch=812, averaged loss=0.111\n",
      "epoch=813, averaged loss=0.111\n",
      "epoch=814, averaged loss=0.111\n",
      "epoch=815, averaged loss=0.111\n",
      "epoch=816, averaged loss=0.111\n",
      "epoch=817, averaged loss=0.111\n",
      "epoch=818, averaged loss=0.111\n",
      "epoch=819, averaged loss=0.111\n",
      "epoch=820, averaged loss=0.111\n",
      "epoch=821, averaged loss=0.111\n",
      "epoch=822, averaged loss=0.111\n",
      "epoch=823, averaged loss=0.111\n",
      "epoch=824, averaged loss=0.111\n",
      "epoch=825, averaged loss=0.110\n",
      "epoch=826, averaged loss=0.110\n",
      "epoch=827, averaged loss=0.110\n",
      "epoch=828, averaged loss=0.110\n",
      "epoch=829, averaged loss=0.110\n",
      "epoch=830, averaged loss=0.110\n",
      "epoch=831, averaged loss=0.110\n",
      "epoch=832, averaged loss=0.110\n",
      "epoch=833, averaged loss=0.110\n",
      "epoch=834, averaged loss=0.110\n",
      "epoch=835, averaged loss=0.110\n",
      "epoch=836, averaged loss=0.110\n",
      "epoch=837, averaged loss=0.110\n",
      "epoch=838, averaged loss=0.109\n",
      "epoch=839, averaged loss=0.109\n",
      "epoch=840, averaged loss=0.109\n",
      "epoch=841, averaged loss=0.109\n",
      "epoch=842, averaged loss=0.109\n",
      "epoch=843, averaged loss=0.109\n",
      "epoch=844, averaged loss=0.109\n",
      "epoch=845, averaged loss=0.109\n",
      "epoch=846, averaged loss=0.109\n",
      "epoch=847, averaged loss=0.109\n",
      "epoch=848, averaged loss=0.109\n",
      "epoch=849, averaged loss=0.109\n",
      "epoch=850, averaged loss=0.109\n",
      "epoch=851, averaged loss=0.108\n",
      "epoch=852, averaged loss=0.108\n",
      "epoch=853, averaged loss=0.108\n",
      "epoch=854, averaged loss=0.108\n",
      "epoch=855, averaged loss=0.108\n",
      "epoch=856, averaged loss=0.108\n",
      "epoch=857, averaged loss=0.108\n",
      "epoch=858, averaged loss=0.108\n",
      "epoch=859, averaged loss=0.108\n",
      "epoch=860, averaged loss=0.108\n",
      "epoch=861, averaged loss=0.108\n",
      "epoch=862, averaged loss=0.108\n",
      "epoch=863, averaged loss=0.108\n",
      "epoch=864, averaged loss=0.108\n",
      "epoch=865, averaged loss=0.107\n",
      "epoch=866, averaged loss=0.107\n",
      "epoch=867, averaged loss=0.107\n",
      "epoch=868, averaged loss=0.107\n",
      "epoch=869, averaged loss=0.107\n",
      "epoch=870, averaged loss=0.107\n",
      "epoch=871, averaged loss=0.107\n",
      "epoch=872, averaged loss=0.107\n",
      "epoch=873, averaged loss=0.107\n",
      "epoch=874, averaged loss=0.107\n",
      "epoch=875, averaged loss=0.107\n",
      "epoch=876, averaged loss=0.107\n",
      "epoch=877, averaged loss=0.107\n",
      "epoch=878, averaged loss=0.107\n",
      "epoch=879, averaged loss=0.106\n",
      "epoch=880, averaged loss=0.106\n",
      "epoch=881, averaged loss=0.106\n",
      "epoch=882, averaged loss=0.106\n",
      "epoch=883, averaged loss=0.106\n",
      "epoch=884, averaged loss=0.106\n",
      "epoch=885, averaged loss=0.106\n",
      "epoch=886, averaged loss=0.106\n",
      "epoch=887, averaged loss=0.106\n",
      "epoch=888, averaged loss=0.106\n",
      "epoch=889, averaged loss=0.106\n",
      "epoch=890, averaged loss=0.106\n",
      "epoch=891, averaged loss=0.106\n",
      "epoch=892, averaged loss=0.106\n",
      "epoch=893, averaged loss=0.105\n",
      "epoch=894, averaged loss=0.105\n",
      "epoch=895, averaged loss=0.105\n",
      "epoch=896, averaged loss=0.105\n",
      "epoch=897, averaged loss=0.105\n",
      "epoch=898, averaged loss=0.105\n",
      "epoch=899, averaged loss=0.105\n",
      "epoch=900, averaged loss=0.105\n",
      "epoch=901, averaged loss=0.105\n",
      "epoch=902, averaged loss=0.105\n",
      "epoch=903, averaged loss=0.105\n",
      "epoch=904, averaged loss=0.105\n",
      "epoch=905, averaged loss=0.105\n",
      "epoch=906, averaged loss=0.105\n",
      "epoch=907, averaged loss=0.105\n",
      "epoch=908, averaged loss=0.104\n",
      "epoch=909, averaged loss=0.104\n",
      "epoch=910, averaged loss=0.104\n",
      "epoch=911, averaged loss=0.104\n",
      "epoch=912, averaged loss=0.104\n",
      "epoch=913, averaged loss=0.104\n",
      "epoch=914, averaged loss=0.104\n",
      "epoch=915, averaged loss=0.104\n",
      "epoch=916, averaged loss=0.104\n",
      "epoch=917, averaged loss=0.104\n",
      "epoch=918, averaged loss=0.104\n",
      "epoch=919, averaged loss=0.104\n",
      "epoch=920, averaged loss=0.104\n",
      "epoch=921, averaged loss=0.104\n",
      "epoch=922, averaged loss=0.104\n",
      "epoch=923, averaged loss=0.103\n",
      "epoch=924, averaged loss=0.103\n",
      "epoch=925, averaged loss=0.103\n",
      "epoch=926, averaged loss=0.103\n",
      "epoch=927, averaged loss=0.103\n",
      "epoch=928, averaged loss=0.103\n",
      "epoch=929, averaged loss=0.103\n",
      "epoch=930, averaged loss=0.103\n",
      "epoch=931, averaged loss=0.103\n",
      "epoch=932, averaged loss=0.103\n",
      "epoch=933, averaged loss=0.103\n",
      "epoch=934, averaged loss=0.103\n",
      "epoch=935, averaged loss=0.103\n",
      "epoch=936, averaged loss=0.103\n",
      "epoch=937, averaged loss=0.103\n",
      "epoch=938, averaged loss=0.103\n",
      "epoch=939, averaged loss=0.102\n",
      "epoch=940, averaged loss=0.102\n",
      "epoch=941, averaged loss=0.102\n",
      "epoch=942, averaged loss=0.102\n",
      "epoch=943, averaged loss=0.102\n",
      "epoch=944, averaged loss=0.102\n",
      "epoch=945, averaged loss=0.102\n",
      "epoch=946, averaged loss=0.102\n",
      "epoch=947, averaged loss=0.102\n",
      "epoch=948, averaged loss=0.102\n",
      "epoch=949, averaged loss=0.102\n",
      "epoch=950, averaged loss=0.102\n",
      "epoch=951, averaged loss=0.102\n",
      "epoch=952, averaged loss=0.102\n",
      "epoch=953, averaged loss=0.102\n",
      "epoch=954, averaged loss=0.102\n",
      "epoch=955, averaged loss=0.101\n",
      "epoch=956, averaged loss=0.101\n",
      "epoch=957, averaged loss=0.101\n",
      "epoch=958, averaged loss=0.101\n",
      "epoch=959, averaged loss=0.101\n",
      "epoch=960, averaged loss=0.101\n",
      "epoch=961, averaged loss=0.101\n",
      "epoch=962, averaged loss=0.101\n",
      "epoch=963, averaged loss=0.101\n",
      "epoch=964, averaged loss=0.101\n",
      "epoch=965, averaged loss=0.101\n",
      "epoch=966, averaged loss=0.101\n",
      "epoch=967, averaged loss=0.101\n",
      "epoch=968, averaged loss=0.101\n",
      "epoch=969, averaged loss=0.101\n",
      "epoch=970, averaged loss=0.101\n",
      "epoch=971, averaged loss=0.100\n",
      "epoch=972, averaged loss=0.100\n",
      "epoch=973, averaged loss=0.100\n",
      "epoch=974, averaged loss=0.100\n",
      "epoch=975, averaged loss=0.100\n",
      "epoch=976, averaged loss=0.100\n",
      "epoch=977, averaged loss=0.100\n",
      "epoch=978, averaged loss=0.100\n",
      "epoch=979, averaged loss=0.100\n",
      "epoch=980, averaged loss=0.100\n",
      "epoch=981, averaged loss=0.100\n",
      "epoch=982, averaged loss=0.100\n",
      "epoch=983, averaged loss=0.100\n",
      "epoch=984, averaged loss=0.100\n",
      "epoch=985, averaged loss=0.100\n",
      "epoch=986, averaged loss=0.100\n",
      "epoch=987, averaged loss=0.100\n",
      "epoch=988, averaged loss=0.099\n",
      "epoch=989, averaged loss=0.099\n",
      "epoch=990, averaged loss=0.099\n",
      "epoch=991, averaged loss=0.099\n",
      "epoch=992, averaged loss=0.099\n",
      "epoch=993, averaged loss=0.099\n",
      "epoch=994, averaged loss=0.099\n",
      "epoch=995, averaged loss=0.099\n",
      "epoch=996, averaged loss=0.099\n",
      "epoch=997, averaged loss=0.099\n",
      "epoch=998, averaged loss=0.099\n",
      "epoch=999, averaged loss=0.099\n",
      "epoch=1000, averaged loss=0.099\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epoches+1):\n",
    "    \n",
    "    total_loss = total_weight_grad = total_bias_grad = 0\n",
    "    count = 0\n",
    "    \n",
    "    for x, y in trainset:\n",
    "        \n",
    "        # 得到模型预测结果o\n",
    "        o = forward(x, weight, bias)\n",
    "        \n",
    "        # 计算损失函数loss\n",
    "        loss = cross_entropy_loss(y, o)\n",
    "        \n",
    "        # 计算梯度\n",
    "        weight_grad, bias_grad = backward(x, o, y, weight, bias)\n",
    "        \n",
    "        count += 1\n",
    "        total_loss += loss\n",
    "        total_weight_grad += weight_grad\n",
    "        total_bias_grad += bias_grad\n",
    "    \n",
    "    # TODO：利用total_weight_grad和weight_grad对weight和bias做更新，实现SGD公式\n",
    "    weight = weight - learning_rate * total_weight_grad\n",
    "    bias = bias - learning_rate * total_bias_grad\n",
    "    \n",
    "    avg_loss = total_loss / count\n",
    "    print('epoch=%d, averaged loss=%.3f' % (epoch, avg_loss))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73ca77",
   "metadata": {},
   "source": [
    "# 任务5：验证模型准确度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73364673",
   "metadata": {},
   "source": [
    "## 实现准确度计算模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ff5b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(weight, bias, dataset):\n",
    "    # 返回模型在数据集上的预测准确率\n",
    "    \n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for x, y in dataset:\n",
    "        \n",
    "        # TODO1：获取模型预测结果\n",
    "        o = forward(x, weight, bias)\n",
    "        \n",
    "        # 取出模型置信度最大是哪个维度\n",
    "        result = np.argmax(o)\n",
    "        \n",
    "        # TODO2：如果result等于y，则correct+1；count不管判断正确与否始终+1\n",
    "        if result == y:\n",
    "            correct += 1\n",
    "        count += 1\n",
    "\n",
    "    acc = correct / count\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520720c5",
   "metadata": {},
   "source": [
    "## 计算准确度 \n",
    "计算并输出模型在trainset和test上的预测准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6649540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9866666666666667 1.0\n"
     ]
    }
   ],
   "source": [
    "train_acc = calc_accuracy(weight, bias, trainset)\n",
    "test_acc = calc_accuracy(weight, bias, testset)\n",
    "\n",
    "print(train_acc, test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
